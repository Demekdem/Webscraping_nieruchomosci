{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1259dbe-7fac-46d6-bb94-6e91bd7c609f",
   "metadata": {},
   "source": [
    "# 📊 Analiza danych nieruchomości\n",
    "Celem projektu jest zebranie danych ze strony Gratka.pl oraz ich analiza: tytuł, opis ceny, metraż. Zebrane dane będa z Wielkopolski."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49520765-7823-4462-9aa1-751e6ef57abe",
   "metadata": {},
   "source": [
    "1.Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e688c7-b602-4248-bfd7-b560d0e319ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb7ff6-a987-4c3d-bdb4-10c48336d924",
   "metadata": {},
   "source": [
    " 2. Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc9bbf9-bdea-4124-9ee9-692312fe9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pobieram stronę 1/1: https://gratka.pl/nieruchomosci/mieszkania/wielkopolskie?sort=relevance\n",
      "Bład na stronie 1: name 'soup' is not defined\n"
     ]
    }
   ],
   "source": [
    "dane = [] \n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "base_url = 'https://gratka.pl/nieruchomosci/mieszkania/wielkopolskie'\n",
    "start_url = f\"{base_url}?sort=relevance\"\n",
    "\n",
    "response = requests.get(start_url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "pagination_links = soup.select('a.pagination__item')\n",
    "page_numbers = [int(link.text.strip()) for link in pagination_links if link.text.strip().isdigit()]\n",
    "max_page = max(page_numbers) if page_numbers else 1\n",
    "\n",
    "for page in range(1, max_page + 1):\n",
    "    if page == 1:\n",
    "        url = start_url\n",
    "    else:\n",
    "        url = f'{base_url}?page={page}&sort=relevance'\n",
    "\n",
    "    print(f\"Pobieram stronę {page}/{max_page}: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        #Tytuły\n",
    "        tytuly = [t.text for t in soup.find_all(class_=\"ehj8iw\")]\n",
    "        #Opisy\n",
    "        opisy = [\n",
    "            o.text.strip.split(\"Dodane\")[0].strip().replace(\"Zobacz opis\", \"\")\n",
    "            for o in soup.find_all(class_=\"ORSCPR\")\n",
    "        ]\n",
    "        #Ceny\n",
    "        ceny = []\n",
    "        for c in soup.find_all(class_=\"vQszq7\"):\n",
    "            tekst = c.text.replace(\" \", \"\")\n",
    "            match = re.match(r\"(\\d+)zł/m²(\\d+)zł\", tekst)\n",
    "            if match:\n",
    "                ceny.append(int(match.group(2)))\n",
    "        #Metraże\n",
    "        metraze = []\n",
    "        for m in soup.find_all(class_=\"oaZarI\"):\n",
    "            match = re.search(r\"(\\d+)\\s?m²\", m.text)\n",
    "            if match:\n",
    "                metraze.append(int(match.group(1)))\n",
    "\n",
    "        # Zgranie danych z mozliwioscia dodania pustych pol\n",
    "        max_len = max(len(tytuly), len(opisy), len(ceny), len(metraze))\n",
    "        for i in range(max_len):\n",
    "            dane.append({\n",
    "                'Tytuł': tytuly[i] if i < len(tytuly) else None,\n",
    "                'Opis': opisy[i] if i < len(opisy) else None,\n",
    "                'Cena': ceny[i] if i < len(ceny) else None,\n",
    "                'Metraż': metraze[i] if i < len(metraze) else None\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Bład na stronie {page}: {e}\")\n",
    "\n",
    "    # Opoznienie miedzy zapytania \n",
    "    time.sleep(1.5)\n",
    "\n",
    "df_gratka = pd.DataFrame(dane)\n",
    "df_gratka.to_csv('gratka_mieszkania.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3d02b-668e-4443-9461-b8afbce3a29f",
   "metadata": {},
   "source": [
    " 3. Pobieranie zbioru danych z Kaggle (polskie nieruchomosci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "616ecc8e-7e34-4af3-aa7f-92f3c8135c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/polska_mieszkania.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_kaggle = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/polska_mieszkania.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/polska_mieszkania.csv'"
     ]
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv(\"data/polska_mieszkania.csv\", sep=';', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bb125-e9d3-41bd-8bf0-73cb4f709052",
   "metadata": {},
   "source": [
    "4. Przygotowanie danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cb7eea7-409a-4efb-a915-4a577aec34bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_kaggle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_kaggle = \u001b[43mdf_kaggle\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33maddress\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msq\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m      2\u001b[39m df_kaggle = df_kaggle.rename(columns={\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maddress\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mTytuł\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mOpis\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mCena\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msq\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mMetraż\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m })\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Usuwam duplikaty ofert\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_kaggle' is not defined"
     ]
    }
   ],
   "source": [
    "df_kaggle = df_kaggle[['address', 'city', 'price', 'sq']]\n",
    "df_kaggle = df_kaggle.rename(columns={\n",
    "    'address': 'Tytuł',\n",
    "    'city': 'Opis',\n",
    "    'price': 'Cena',\n",
    "    'sq': 'Metraż'\n",
    "})\n",
    "\n",
    "# Usuwam duplikaty ofert\n",
    "df_gratka.drop_duplicate(subset=['Tytuł', 'Cena', 'Metraż'], keep=first, inplace=True)\n",
    "df_kaggle.drop_duplciate(subset=['Tytuł', 'Cena', 'Metraż'], keep=first, inplace=True)\n",
    "\n",
    "# Usuwam oferty, które nie maja podanej ceny lub metrażu\n",
    "df_gratka.dropna(subset=['Cena', 'Metraż'], how='any', inplace=True)\n",
    "df_kaggle.dropna(subset=['Cena', 'Metraż'], how='any', inplace=True)\n",
    "\n",
    "# Standaryzacja zmiennej - cena \n",
    "#print(df_gratka['Cena'].dtype)\n",
    "#print(df_kaggle['Cena'].dtype)\n",
    "df_gratka['Cena'] = df_gratka['Cena'].round(0).astype('Int64')\n",
    "df_kaggle['Cena'] = df_kaggle['Cena'].round(0).astype('Int64')\n",
    "\n",
    "# Standaryzacja zmiennej - metraż\n",
    "#print(df_gratka['Metraż'].dtype)       - int64\n",
    "#print(df_kaggle['Metraż'].dtype)       - float64\n",
    "df_gratka['Metraż'] = df_gratka['Metraż'].round(2).astype('Float64')\n",
    "\n",
    "# Oczyszanie zmiennych tytul i opis z zbednych znaków \n",
    "def oczyszczony_tekst(tekst):\n",
    "    tekst = re.sub(r'<[^>]+>', '', tekst)\n",
    "    tekst = re.sub(r'[^\\w\\sąćęłńóśżźĄĆĘŁŃÓŚŻŹ]', '', tekst)\n",
    "    tekst = re.sub(r'\\s+', '', tekst)\n",
    "    return tekst.strip()\n",
    "\n",
    "df_gratka['Tytuł'] = df_gratka['Tytuł'].astype(str).apply(oczyszczony_tekst)\n",
    "df_gratka['Opis'] = df_gratka['Opis'].astype(str).apply(oczyszczony_tekst)\n",
    "\n",
    "df_kaggle['Tytuł'] = df_kaggle['Tytuł'].astype(str).apply(oczyszczony_teskt)\n",
    "df_kaggle['Opis'] = df_kaggle['Opis'].astype(str).apply(oczyszczony_tekst)\n",
    "\n",
    "# Zidentikuje i usune podejrzane oferty \n",
    "min_price = 100000\n",
    "max_price = 10000000\n",
    "min_sq = 10\n",
    "max_sq = 200\n",
    "\n",
    "df_gratka = df_gratka[\n",
    "    (df_gratka['Cena'] >= min_price) &\n",
    "    (df_gratka['Cena'] <= max_price) &\n",
    "    (df_gratka['Metraż'] >= min_sq) &\n",
    "    (df_gratka['Metraż'] <= max_sq)\n",
    "]\n",
    "\n",
    "df_kaggle = df_kaggle[\n",
    "    df_kaggle['Cena'] >= min_price &\n",
    "    df_kaggle['Cena'] <= max_price &\n",
    "    df_kaggle['Metraż'] >= min_sq &\n",
    "    df_kaggle['Metraż'] <= max_sq\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55926d27-e905-430d-99a0-e63f174ead69",
   "metadata": {},
   "source": [
    "5. Zapisanie danych do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d40581-6d29-44d4-8881-885b2d9b1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gratka.to_csv(\"gotowe_nieruchomosci.csv\", index=False)\n",
    "df_kaggle.to_csv(\"gotowe_kaggle.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
